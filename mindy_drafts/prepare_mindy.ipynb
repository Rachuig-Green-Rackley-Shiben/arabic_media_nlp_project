{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c0cfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from camel_tools.utils.normalize import normalize_unicode\n",
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from camel_tools.utils.normalize import normalize_unicode\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/block_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880febcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cc6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2271334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/sample_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22596ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize arabic characters\n",
    "df['characters'] = df['text'].apply(normalize_unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b643be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthographic Normalization (alef and teh_marbuta)\n",
    "df['normalize_alef'] = (df['characters'].apply(normalize_alef_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove diacritics\n",
    "df['remove_diacritics'] = (df['normalize_alef'].apply(dediac_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split word tokenizer\n",
    "#use sentence.split() as option to include punctuation with closest word, ie. ? at end of sentense w/word\n",
    "\n",
    "df['words_split'] = (df['remove_diacritics'].apply(simple_word_tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e54841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec60e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.ner import NERecognizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.ner import NERecognizer\n",
    "\n",
    "ner = NERecognizer.pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.isri import ISRIStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ar(text):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    st = ISRIStemmer()\n",
    "    \n",
    "    for t in text:\n",
    "        t = ''.join(c for c in t if ud.category(c) == 'Lo' or ud.category(c) == 'Nd' or c == ' ')\n",
    "\n",
    "    commentwords = ''\n",
    "    for word in t.split():\n",
    "            # Checking if the word is a stopword.\n",
    "        if word not in stopwords :\n",
    "            if len(word)>1:\n",
    "                    # Lemmatizing the word.\n",
    "                word = st.suf32(word)\n",
    "                commentwords += (word+' ')\n",
    "    processedText.append(commentwords)\n",
    "    \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = (df['text'].apply(preprocess_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "133dfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qalsadi.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c31a5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "    lemmas = lemmer.lemmatize_text(text)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = (df['text'].apply(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "\n",
    "\n",
    "word_list = \"عرض يستخدم الى التفاعل مع المستخدمين في هاذا المجال !وعلمآ تكون الخدمه للستطلاع على الخدمات والعروض المقدمة\"\n",
    "\n",
    "# Define a function\n",
    "def filter(text):\n",
    "    st = ISRIStemmer()\n",
    "    wordsfilter = []\n",
    "    for a in word_tokenize(text):\n",
    "        stem = st.stem(a)\n",
    "        wordsfilter.append(stem)\n",
    "    print(wordsfilter)\n",
    "\n",
    "# Call the function\n",
    "filter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isri_tokens'] = (df['text'].apply(filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8df21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.api import StemmerI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = (normalize_unicode(string))\n",
    "\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f61946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    st = nltk.stem.isri.ISRIStemmer()\n",
    "    stems = [st.stem(word) for word in string.split()]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_arabic(df, column):\n",
    "\n",
    "    df = df.dropna()\n",
    "    clean_tokens = (df[column].apply(basic_clean)\n",
    ")\n",
    "    \n",
    "    for token in clean_tokens:\n",
    "        token = ' '.join(token).split()\n",
    "    \n",
    "    df['lemmatized'] = clean_tokens.apply(lemmatize)\n",
    "    df['total_words'] = df['lemmatized'].str.split().str.len()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_arabic(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa718551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/sample_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085dc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df.lemmatized.apply(str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df269024",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = basic_clean(' '.join(df.lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f329af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline   \n",
    "from camel_tools.sentiment import SentimentAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Change name to which file you're doing sentiment analysis on, NOT including the '.csv' \n",
    "Output file will be 'labeled_<filename>.csv'\n",
    "\"\"\"\n",
    "\n",
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'block_3'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    print(f'loaded {name}.csv')\n",
    "    print('labeling/scoring...')\n",
    "    df = create_labels_scores(df, name)\n",
    "    print('done labeling/scoring!')\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (test_1[0]['score'] + test_2[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "        \n",
    "            try:\n",
    "                beginning = msa(df_text[:round(len(df_text)/3)]) \n",
    "                middle = msa(df_text[round(len(df_text)/3):round(len(df_text)*2/3)])\n",
    "                end = msa(df_text[round(len(df_text)*2/3):])\n",
    "\n",
    "                if (beginning[0]['label'] == middle[0]['label']) and (beginning[0]['label'] == end[0]['label']):\n",
    "                    label = first_half[0]['label']\n",
    "                    score = (beginning[0]['score'] + middle[0]['score'] + end[0]['score'])/3\n",
    "                    done = [{'label': label, 'score': score}]\n",
    "                    return done\n",
    "                return False\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    for val in msa_scores.values:\n",
    "        try:\n",
    "            label.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            label.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "        return label, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    label, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = label\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    label, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = label\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_'+ name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda183d",
   "metadata": {},
   "source": [
    "create_labels_scores(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27614f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline   \n",
    "from camel_tools.sentiment import SentimentAnalyzer \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3dc9bb",
   "metadata": {},
   "source": [
    "\"\"\" \n",
    "Change name to which file you're doing sentiment analysis on, NOT including the '.csv' \n",
    "Output file will be 'labeled_<filename>.csv'\n",
    "\"\"\"\n",
    "\n",
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'block_3_trial'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    print(f'loaded {name}.csv')\n",
    "    print('labeling/scoring...')\n",
    "    df = create_labels_scores(df, name)\n",
    "    print('done labeling/scoring!')\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (test_1[0]['score'] + test_2[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "        \n",
    "            try:\n",
    "                beginning = msa(df_text[:round(len(df_text)/3)]) \n",
    "                middle = msa(df_text[round(len(df_text)/3):round(len(df_text)*2/3)])\n",
    "                end = msa(df_text[round(len(df_text)*2/3):])\n",
    "\n",
    "                if (beginning[0]['label'] == middle[0]['label']) and (beginning[0]['label'] == end[0]['label']):\n",
    "                    label = first_half[0]['label']\n",
    "                    score = (beginning[0]['score'] + middle[0]['score'] + end[0]['score'])/3\n",
    "                    done = [{'label': label, 'score': score}]\n",
    "                    return done\n",
    "                return False\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    for val in msa_scores.values:\n",
    "        try:\n",
    "            label.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            label.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "        return label, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    label, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = label\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    label, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = label\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_trial'+ name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e29a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/block_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e71b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47f36ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1 = df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0be8d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1.to_csv('block_3_part_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45a98266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 5000\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        5000 non-null   object\n",
      " 1   url       5000 non-null   object\n",
      " 2   headline  5000 non-null   object\n",
      " 3   dateline  5000 non-null   object\n",
      " 4   text      5000 non-null   object\n",
      " 5   tags      5000 non-null   object\n",
      " 6   source    5000 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 312.5+ KB\n"
     ]
    }
   ],
   "source": [
    "subset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18f5bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf4ad36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'subset_1'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    print(f'loaded {name}.csv')\n",
    "    print('labeling/scoring...')\n",
    "    df = create_labels_scores(df, name)\n",
    "    print('done labeling/scoring!')\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['text_label'] = 'invalid'\n",
    "    df['text_score'] = 'invalid'\n",
    "    df['headline_label'] = 'invalid'\n",
    "    df['headline_score'] = 'invalid'\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (first_half[0]['score'] + second_half[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "            return [{'label': 'unlabeled', 'score': 'unscored'}]\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for val in msa_scores:\n",
    "        try:\n",
    "            labels.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            labels.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "    return labels, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    labels, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = labels\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    labels, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = labels\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_part_1_'+ name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2259ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1 = create_labels_scores(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59d03a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              51 non-null     object \n",
      " 1   url             51 non-null     object \n",
      " 2   headline        51 non-null     object \n",
      " 3   dateline        51 non-null     object \n",
      " 4   text            51 non-null     object \n",
      " 5   tags            51 non-null     object \n",
      " 6   source          51 non-null     object \n",
      " 7   text_label      51 non-null     object \n",
      " 8   text_score      51 non-null     object \n",
      " 9   headline_label  51 non-null     object \n",
      " 10  headline_score  51 non-null     float64\n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fc5f22d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      28\n",
       "unlabeled    14\n",
       "negative      5\n",
       "positive      4\n",
       "Name: text_label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_label.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
