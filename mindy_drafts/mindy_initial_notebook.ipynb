{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1feb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364996f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58290705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "\n",
    "translation = translator.translate(\"مرحبا كيف حالك؟\",  dest='en')\n",
    "translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc0aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/mindyshiben/Documents/Alittihad_utf_8.sgm', 'r')\n",
    "data= f.read()\n",
    "soup = BeautifulSoup(data)\n",
    "topics= soup.findAll('body') # find all body tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf27107",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.sentiment import SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad274475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentAnalyzer(\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "sentences = ['أنا بخير', 'أنا لست بخير']\n",
    "sa.predict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = 'أمريكا فظيعة' #America is terrible\n",
    "sa.predict(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = \"هل يمكننا تناول الغداء؟\" #Can we have lunch?\n",
    "sa.predict(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9832ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 =  \"قال الرئيس الأمريكي بايدن إن الكثيرين سيظلون مصابين بـ COVID-19 ، لكن اللقاحات والاختبارات والعلاج المتاحة جعلت فيروس كورونا أقل فتكًا\"\n",
    "#US President Biden says many will still get COVID-19, but available vaccines, testing and treatment have made the coronavirus less deadly\n",
    "sa.predict(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc63f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_4 = \"مقتل أسامة بن لادن\" \n",
    "#Osama Bin Laden killed\n",
    "#sa.predict(test_4) #this changed \n",
    "sa(test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_5 = \"أسامة بن لادن\" \n",
    "#Osama Bin Laden\n",
    "sa.predict(test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281acdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_6 = \"الرئيس ترامب\"\n",
    "#President Trump\n",
    "sa.predict(test_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade411d",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- It appears all names are neutral\n",
    "- End to terrorism: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_7 = \"االإرهاب\"\n",
    "#terrorism\n",
    "#sa.predict(test_7)\n",
    "sa(test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24aaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_7 = \"الإرهاب خير\"\n",
    "#terrorism is good\n",
    "#sa.predict(test_7)\n",
    "sa(test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea217b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_8 = \"نهاية الإرهاب\"\n",
    "#end to terrorism\n",
    "sa(test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de990e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_9 = \"لقد انتهى الإرهاب\"\n",
    "test_9_en = 'terrorism has ended'\n",
    "test_9 = test_9_en, sa(test_9)\n",
    "test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e370f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b900e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = pipeline('text-classification', model='CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment')\n",
    "sentences = ['أنا بخير', 'أنا لست بخير']\n",
    "print(sa(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa([test_7]), test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa(test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa(test_6) #Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa(test_5) #bin laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d40fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77da997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/mindyshiben/codeup-data-science/Alittihad_XML_CP1256-1/Alittihad_CP1256.xml',  'r', encoding ='CP1256')\n",
    "data= f.read()\n",
    "soup = BeautifulSoup(data)\n",
    "topics= soup.findAll('body') # find all body tags\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8503ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ed51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23eff29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2860da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b384c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21302823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xml_data = open('/Users/mindyshiben/codeup-data-science/Alittihad_XML_CP1256-1/Alittihad_CP1256.xml',  'r', encoding ='CP1256').read()  # Read file\n",
    "root = ET.XML(xml_data)  # Parse XML\n",
    "\n",
    "data = []\n",
    "cols = []\n",
    "for i, child in enumerate(root):\n",
    "    data.append([subchild.text for subchild in child])\n",
    "    cols.append(child.tag)\n",
    "\n",
    "df = pd.DataFrame(data).T  # Write in DF and transpose it\n",
    "df.columns = cols  # Update column names\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abada2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/mindyshiben/codeup-data-science/Alittihad_XML_CP1256-1/Alittihad_CP1256.xml', encoding ='CP1256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71226b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from functools import partial\n",
    "\n",
    "def fast_iter(context, func):\n",
    "    for event, elem in context:\n",
    "        func(elem)\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    del context\n",
    "\n",
    "def printattname(elem, attname):\n",
    "    return elem.attrib[attname]\n",
    "\n",
    "def main(fname, tag, attname):\n",
    "\n",
    "    fun = partial(printattname, attname=attname)\n",
    "    with open(fname) as f:\n",
    "        context = etree.iterparse(f, events=(\"end\",), tag=tag)\n",
    "        fast_iter(context, fun)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from docopt import docopt\n",
    "    main(args[\"<xmlfile>\"], args[\"<tag>\"], args[\"<attname>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xml.etree.ElementTree import iterparse\n",
    "#from cElementTree import iterparse          # POSSIBLY FASTER\n",
    "\n",
    "filename = file\n",
    "data = []\n",
    "\n",
    "for event, elem in iterparse(filename,  events=(\"start\", \"end\")):    \n",
    "    if elem.tag == \"TimeStep\" and event == 'start':\n",
    "        TS = elem.attrib['TS']\n",
    "        elem.clear()\n",
    "        \n",
    "    if elem.tag == \"Particle\" and event == 'start':\n",
    "        cdata = elem.text.split(',')\n",
    "        data.append([TS, elem.attrib['PT'], cdata[0], cdata[1]])\n",
    "        elem.clear()\n",
    "\n",
    "mat = np.array(data).astype(np.float)   \n",
    "print(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = xml.sax.make_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc276b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self._charBuffer = []\n",
    "        self._result = []\n",
    "\n",
    "    def _getCharacterData(self):\n",
    "        data = ''.join(self._charBuffer).strip()\n",
    "        self._charBuffer = []\n",
    "        return data.strip() #remove strip() if whitespace is important\n",
    "\n",
    "    def parse(self, f):\n",
    "        xml.sax.parse(f, self)\n",
    "        return self._result\n",
    "\n",
    "    def characters(self, data):\n",
    "        self._charBuffer.append(data)\n",
    "\n",
    "#     def startElement(self, name, attrs):\n",
    "#         if name == 'job': self._result.append({})\n",
    "\n",
    "#     def endElement(self, name):\n",
    "#         if not name == 'job': self._result[-1][name] = self._getCharacterData()\n",
    "\n",
    "jobs = MyHandler().parse('/Users/mindyshiben/Documents/Alittihad_utf_8.sgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53366295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "pyautogui.PAUSE = 15\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "\n",
    "while True:\n",
    "    pyautogui.moveTo(100, 200, 2)\n",
    "    pyautogui.moveTo(200,100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26438206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline   \n",
    "from camel_tools.sentiment import SentimentAnalyzer \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115eee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/block_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee62fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('block_3_part_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1b783",
   "metadata": {},
   "source": [
    "\"\"\" \n",
    "Change name to which file you're doing sentiment analysis on, NOT including the '.csv' \n",
    "Output file will be 'labeled_<filename>.csv'\n",
    "\"\"\"\n",
    "\n",
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'block_3_part_1'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    print(f'loaded {name}.csv')\n",
    "    print('labeling/scoring...')\n",
    "    df = create_labels_scores(df, name)\n",
    "    print('done labeling/scoring!')\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (test_1[0]['score'] + test_2[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "        \n",
    "            try:\n",
    "                beginning = msa(df_text[:round(len(df_text)/3)]) \n",
    "                middle = msa(df_text[round(len(df_text)/3):round(len(df_text)*2/3)])\n",
    "                end = msa(df_text[round(len(df_text)*2/3):])\n",
    "\n",
    "                if (beginning[0]['label'] == middle[0]['label']) and (beginning[0]['label'] == end[0]['label']):\n",
    "                    label = first_half[0]['label']\n",
    "                    score = (beginning[0]['score'] + middle[0]['score'] + end[0]['score'])/3\n",
    "                    done = [{'label': label, 'score': score}]\n",
    "                    return done\n",
    "                return False\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    for val in msa_scores.values:\n",
    "        try:\n",
    "            label.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            label.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "        return label, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    label, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = label\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    label, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = label\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_1_'+ name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f6dde",
   "metadata": {},
   "source": [
    "create_labels_scores(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bfd8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9de31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19774e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069db313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb7410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5d947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78384e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1e1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f8154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bd198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370b0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae18704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mindyshiben/codeup-data-science/arabic_media_nlp_project/block_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a344009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2 = df[5000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90210651",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2.to_csv('block_3_part_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e383ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'subset_2'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    print(f'loaded {name}.csv')\n",
    "    print('labeling/scoring...')\n",
    "    df = create_labels_scores(df, name)\n",
    "    print('done labeling/scoring!')\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df['text_label'] = 'invalid'\n",
    "    df['text_score'] = 'invalid'\n",
    "    df['headline_label'] = 'invalid'\n",
    "    df['headline_score'] = 'invalid'\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (first_half[0]['score'] + second_half[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "            return [{'label': 'unlabeled', 'score': 'unscored'}]\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for val in msa_scores:\n",
    "        try:\n",
    "            labels.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            labels.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "    return labels, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    labels, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = labels\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    labels, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = labels\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_part_2_'+ name + '.csv', index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2 = create_labels_scores(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f8e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
