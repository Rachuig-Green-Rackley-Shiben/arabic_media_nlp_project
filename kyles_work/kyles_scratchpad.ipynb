{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351a8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ahocorasick\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/kylegreen/codeup-data-science/trials_in_rust/trials-in-rust/first_rust_program/Testing/Almustaqbal.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).headline.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faeacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4afa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81933c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb987e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from transformers import pipeline\n",
    "\n",
    "#mix = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-mix-sentiment\")\n",
    "#ca = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-ca-sentiment\")\n",
    "#da = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "\n",
    "#half = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-half\")\n",
    "#quarter = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-quarter\")\n",
    "#eighth = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-eighth\")\n",
    "#sixteenth = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sixteenth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ae015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = (mix, ca, da, msa, half, quarter, eighth, sixteenth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in models:\n",
    "    print(mod('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5).text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7248e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(val.split()) for val in df.head(100).text.values])/100\n",
    "modelable = df.head(2000).text[[True if len(val.split()) < 350 else False for val in df.head(2000).text.values]]\n",
    "for val in modelable.values:\n",
    "    print(msa(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95bad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df.head(200).values:\n",
    "    try:\n",
    "        print(msa(val))\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    #for mod in models:\n",
    "        #print(mod(val[:512]))\n",
    "        \n",
    "subset = df.head(100).copy()\n",
    "\n",
    "        \n",
    "        \n",
    "subset['label'] = subset.apply(lambda x:  msa(x.text)[0]['label'] if len(x.text.split()) < 300 else False, axis=1)\n",
    "subset['score'] = subset.apply(lambda x: msa(x.text)[0]['score'] if len(x.text.split()) < 300 else False, axis=1)\n",
    "subset.head()\n",
    "\n",
    "#texts = {}    \n",
    "#for i, val in enumerate(df.head(200).text.values):\n",
    "#    if len(val) > 35 and len(val) < 512:\n",
    "#        texts[i] = val\n",
    "        \n",
    "        \n",
    "#print(texts)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b269344",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.score.groupby(subset.label).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[subset.label== 'negative'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_english(text):\n",
    "    translation = translator.translate(text, dest='en').text\n",
    "    return translation\n",
    "\n",
    "translate_to_english(subset.head(1).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ed2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('labels.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4337a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "def translate_to_english(text):\n",
    "    translation = translator.translate(text, dest='en').text\n",
    "    return translation\n",
    "\n",
    "def check_for_america(translation):\n",
    "    if 'america' in translation.lower() or 'united states' in translation.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "text = sub.head(1).text\n",
    "\n",
    "\n",
    "\n",
    "#translation = translate_to_english(text)\n",
    "#check_for_america(translation)\n",
    "\n",
    "row_nums = df.shape[0]\n",
    "sets_of_ten = int(row_nums / 100)\n",
    "\n",
    "collection_of_dfs = []\n",
    "print(sets_of_ten)\n",
    "\n",
    "for i in range(0,100):\n",
    "    collection_of_dfs.append(df[df.index.isin(range(i * sets_of_ten, (i+1) * sets_of_ten))].copy())\n",
    "    collection_of_dfs[i]['america'] = [True if val.str.contains('')]\n",
    "    print(collection_of_dfs[f'frame_{i}'])\n",
    "    break\n",
    "    \n",
    "\n",
    "#sub['en_text'] = sub.apply(lambda x: translate_to_english(x.text), axis=1)\n",
    "#sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45899ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbf011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = 'almustaqbal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask].to_csv('almustaqbal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33e802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def flip_key_value_pairs(dicts):\n",
    "    res = dict((v,k) for k,v in dicts.items())\n",
    "    return res\n",
    "\n",
    "def using_ahocorasick(col, lst):\n",
    "    A = ahocorasick.Automaton(ahocorasick.STORE_INTS)\n",
    "    for word in lst:\n",
    "        A.add_word(word.lower())\n",
    "    A.make_automaton() \n",
    "    col = col.astype(str)\n",
    "    col = col.str.lower()\n",
    "    mask = col.apply(lambda x: bool(list(A.iter(x))))\n",
    "    tags = col.apply(lambda x: list(A.iter(x)))\n",
    "    return mask, tags\n",
    "\n",
    "def look_for_words_in_text(df_text):\n",
    "    \n",
    "    topics = {'America' : 'أمريكا',\n",
    "            'American' : 'أمريكيّ',\n",
    "            'American (f)' : 'أمريكيّة',\n",
    "            'American (pl)' : 'أمريكيّين',\n",
    "            'The United States' : 'الولايات المتحدة',\n",
    "            'The United States' : 'دول موحّدة',\n",
    "            'Washington' : 'واشنطن',\n",
    "            'Bush' : 'بوش',\n",
    "            'Obama' : 'أوباما',\n",
    "            'Cheney' : 'تشيني',\n",
    "            'Clinton' : 'كلينتون',\n",
    "            'Osama Bin Laden' : 'أسامة بن لادن',\n",
    "            'Al Gore' : 'آل غور',\n",
    "            'World Trade Center' : 'مركز التجارة العالمي',\n",
    "            '9/11' : '9/11',\n",
    "            'September 11' : '11 سبتمبر',\n",
    "            'Gulf War' : 'حرب الخليج',\n",
    "            'Google' : 'غوغل',\n",
    "            'Facebook' : 'فيسبوك',\n",
    "            'Al Qaida' : 'القاعدة'}\n",
    "    \n",
    "    topics = flip_key_value_pairs(topics)\n",
    "    \n",
    "    tags = []\n",
    "    for key in topics.keys():\n",
    "        if key in df_text:\n",
    "            tags.append(key)\n",
    "            \n",
    "    return tags\n",
    "\n",
    "def make_relevant_tagged_df(df):\n",
    "    topics = {'America' : 'أمريكا',\n",
    "            'American' : 'أمريكيّ',\n",
    "            'American (f)' : 'أمريكيّة',\n",
    "            'American (pl)' : 'أمريكيّين',\n",
    "            'The United States' : 'الولايات المتحدة',\n",
    "            'The United States' : 'دول موحّدة',\n",
    "            'Washington' : 'واشنطن',\n",
    "            'Bush' : 'بوش',\n",
    "            'Obama' : 'أوباما',\n",
    "            'Cheney' : 'تشيني',\n",
    "            'Clinton' : 'كلينتون',\n",
    "            'Osama Bin Laden' : 'أسامة بن لادن',\n",
    "            'Al Gore' : 'آل غور',\n",
    "            'World Trade Center' : 'مركز التجارة العالمي',\n",
    "            '9/11' : '9/11',\n",
    "            'September 11' : '11 سبتمبر',\n",
    "            'Gulf War' : 'حرب الخليج',\n",
    "            'Google' : 'غوغل',\n",
    "            'Facebook' : 'فيسبوك',\n",
    "            'Al Qaida' : 'القاعدة'}\n",
    "\n",
    "\n",
    "    topics = flip_key_value_pairs(topics)\n",
    "    mask, tags = using_ahocorasick(df.text, list(topics.keys()))\n",
    "\n",
    "    copied = df[mask].copy()\n",
    "\n",
    "    copied['tags'] = copied.text.apply(look_for_words_in_text)\n",
    "\n",
    "    return copied\n",
    "\n",
    "publication_names = ['Alittihad', 'Almasryalyoum', 'Almustaqbal', 'Alqabas', 'Echoroukonline', 'Ryiadh', 'Sabanews', 'SaudiYoum', 'Techreen', 'Youm7']\n",
    "\n",
    "filepath = '/Users/kylegreen/codeup-data-science/trials_in_rust/trials-in-rust/first_rust_program/Testing/'\n",
    "\n",
    "for name in publication_names:\n",
    "    path = filepath+name\n",
    "    df = pd.read_csv(path + '.csv')\n",
    "    df = make_relevant_tagged_df(df)\n",
    "    df['source'] = name\n",
    "    df.to_csv(name+'.csv', index=False)\n",
    "    print(name)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea915ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in copied.tags.values:\n",
    "    if len(val) > 1:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0280913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub['america'] = sub.apply(lambda x: check_for_america(x.en_text), axis=1)\n",
    "sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[sub.america==True].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(publication_names[4] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfea368",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = []\n",
    "for name in publication_names:\n",
    "    csvs.append(pd.read_csv(name + '.csv'))\n",
    "df = pd.concat(csvs)\n",
    "df.to_csv('all_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a647f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7915a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(500).to_csv('sample_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(df.shape[0] /3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs = []\n",
    "for i in range(0, df.shape[0] - steps, steps):\n",
    "    split_dfs.append(df.iloc[i: i+steps])\n",
    "    \n",
    "split_dfs[0].text.unique().size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(split_dfs):\n",
    "    d.to_csv(f'block_{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b51510",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (test_1[0]['score'] + test_2[0]['score'])/2\n",
    "                done = [{'label': label, 'score': score}]\n",
    "                return done\n",
    "        except:\n",
    "            print(df_text)\n",
    "            return False\n",
    "        \n",
    "\n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.iloc[0:50].text.apply(make_msa)\n",
    "    #df['score'] = df.text.apply(lambda x: msa(x)[0]['score'] if len(x.split()) < 300 else False)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.iloc[0:200].headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "#(analyze_text(df) != False).sum()\n",
    "(analyze_text(subset_df) != False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= 'ائيل عن وثائق جديدة اليوم، السبت، عن أسرار حرب الاستنزاف التى خاضتها مصر ض'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9684af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = pd.read_csv('sample_articles.csv')\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a16c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2708bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in subset_df.text.values:\n",
    "    if text in val:\n",
    "        print(subset_df[subset_df.text==val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a14d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dicts = {}\n",
    "for source in df.source.unique():\n",
    "    source_dicts[source] = df[df.source == source]\n",
    "    \n",
    "source_dicts['SaudiYoum']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e373c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dateline.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in list(df.dateline.values):\n",
    "    try:\n",
    "        print(re.search('20\\d\\d\\W\\d\\d\\W\\d\\d', val).group())\n",
    "        \n",
    "    except:\n",
    "        print(val)\n",
    "\n",
    "#print(len(df.dateline.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff81df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dicts['SaudiYoum'].dateline.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d209b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def using_ahocorasick_months(col, lst):\n",
    "    A = ahocorasick.Automaton(ahocorasick.STORE_INTS)\n",
    "    for word in lst:\n",
    "        A.add_word(word.lower())\n",
    "    A.make_automaton() \n",
    "    col = col.astype(str)\n",
    "    col = col.str.lower()\n",
    "    mask = col.apply(lambda x: bool(list(A.iter(x))))\n",
    "    return mask\n",
    "\n",
    "def look_for_words_in_text_months(df_text):\n",
    "    \n",
    "    months = {'January' : 'يناير',\n",
    "                        'February' : 'فبراير',\n",
    "                        'March' : 'مارس',\n",
    "                        'April' : 'أبريل',\n",
    "                        'June' : 'يوني',\n",
    "                        'July' : 'يولي',\n",
    "                        'August' : 'أغسطس',\n",
    "                        'September' : 'سبتمبر',\n",
    "                        'October' : 'أكتوبر',\n",
    "                        'November' : 'نوفمبر',\n",
    "                        'December' : 'ديسمبر',\n",
    "                        'April1' : 'إبريل',\n",
    "                        'May': 'ماي'}\n",
    "    \n",
    "    months = flip_key_value_pairs(months)\n",
    "    \n",
    "    tags = []\n",
    "    for key in months.keys():\n",
    "        if key in df_text:\n",
    "            tags.append(key)\n",
    "            \n",
    "    return tags\n",
    "\n",
    "mask = using_ahocorasick(df.dateline, list(months.values()))[0]\n",
    "copy = df[mask].copy()\n",
    "copy = pd.DataFrame(copy)\n",
    "copy['month'] = copy.dateline.apply(look_for_words_in_text_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81542df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a193de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_month(df_dateline):\n",
    "    exp = '\\d\\d.*\\d\\d\\d\\d'\n",
    "    try:\n",
    "        month = re.search(exp, df_dateline).group()[2:-4]\n",
    "        months = {'January' : 'يناير',\n",
    "                        'February' : 'فبراير',\n",
    "                        'March' : 'مارس',\n",
    "                        'April' : 'أبريل',\n",
    "                        'June' : 'يوني',\n",
    "                        'July' : 'يولي',\n",
    "                        'August' : 'أغسطس',\n",
    "                        'September' : 'سبتمبر',\n",
    "                        'October' : 'أكتوبر',\n",
    "                        'November' : 'نوفمبر',\n",
    "                        'December' : 'ديسمبر',\n",
    "                        'April1' : 'إبريل',\n",
    "                        'May': 'ماي'}\n",
    "    \n",
    "        months = flip_key_value_pairs(months)\n",
    "        \n",
    "        return re.search(exp, df_dateline).group()[2:-4]\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            return re.search('20\\d\\d\\W\\d\\d\\W\\d\\d', val).group()\n",
    "\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "df.dateline.apply(find_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dateline.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce080410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('all_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cf033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "from camel_tools.sentiment import SentimentAnalyzer\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Change name to which file you're doing sentiment analysis on, NOT including the '.csv' \n",
    "Output file will be 'labeled_<filename>.csv'\n",
    "\"\"\"\n",
    "\n",
    "msa = pipeline('text-classification', model=\"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\")\n",
    "name = 'block_1'\n",
    "\n",
    "\n",
    "def load_and_label_df(name):\n",
    "    df = load_csv(name+'.csv')\n",
    "    df = create_labels_scores(df, name)\n",
    "    return df\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def make_msa(df_text):\n",
    "    try:\n",
    "        done = msa(df_text)\n",
    "        return done\n",
    "    except:\n",
    "        \n",
    "        try:\n",
    "            first_half = msa(df_text[:round(len(df_text)/2)]) \n",
    "            second_half = msa(df_text[round(len(df_text)/2):])\n",
    "            if first_half[0]['label'] == second_half[0]['label']:\n",
    "                label = first_half[0]['label']\n",
    "                score = (test_1[0]['score'] + test_2[0]['score'])/2\n",
    "            done = [{'label': label, 'score': score}]\n",
    "            return done\n",
    "        except:\n",
    "        \n",
    "            try:\n",
    "                beginning = msa(df_text[:round(len(df_text)/3)]) \n",
    "                middle = msa(df_text[round(len(df_text)/3):round(len(df_text)*2/3)])\n",
    "                end = msa(df_text[round(len(df_text)*2/3):])\n",
    "\n",
    "                if (beginning[0]['label'] == middle[0]['label']) and (beginning[0]['label'] == end[0]['label']):\n",
    "                    label = first_half[0]['label']\n",
    "                    score = (beginning[0]['score'] + middle[0]['score'] + end[0]['score'])/3\n",
    "                    done = [{'label': label, 'score': score}]\n",
    "                    return done\n",
    "                return False\n",
    "            except:\n",
    "                return False\n",
    "        \n",
    "def analyze_text(df):\n",
    "    scores = []\n",
    "    scores = df.text.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def analyze_headline(df):\n",
    "    headline_scores = []\n",
    "    scores = df.headline.apply(make_msa)\n",
    "    return scores\n",
    "\n",
    "def label_and_scores(msa_scores):\n",
    "    for val in msa_scores.values:\n",
    "        try:\n",
    "            labels.append(val[0]['label'])\n",
    "            scores.append(val[0]['score'])\n",
    "        except:\n",
    "            labels.append(False)\n",
    "            scores.append(False)\n",
    "\n",
    "        return labels, scores\n",
    "\n",
    "def create_labels_scores(df, name):\n",
    "    text_scores = analyze_text(df)\n",
    "    labels, scores = label_and_scores(text_scores)\n",
    "    df['text_label'] = labels\n",
    "    df['text_score'] = scores\n",
    "\n",
    "    headline_scores = analyze_headline(df)\n",
    "    labels, scores = label_and_scores(headline_scores)\n",
    "    df['headline_label'] = labels\n",
    "    df['headline_score'] = scores\n",
    "\n",
    "    # CHANGE 'BLOCK_NAME' TO WHATEVER YOU WANT\n",
    "    df.to_csv('labeled_'+ name + '.csv', index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "load_and_label_df(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee65ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
